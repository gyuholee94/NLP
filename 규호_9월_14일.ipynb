{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "규호 9월 14일.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyuholee94/NLP/blob/master/%EA%B7%9C%ED%98%B8_9%EC%9B%94_14%EC%9D%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7myfNyUdwt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c19b58da-078f-4850-a2f0-a22303db3bf2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import datetime\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, BatchNormalization, Dropout, MaxPool2D, Activation,\n",
        "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add, AveragePooling2D\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models,datasets\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "\n",
        "## Tensorflow ## \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical \n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array \n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import cv2\n",
        "import os\n",
        "from random import *\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyBSP4GdeED5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8ddcd447-ccbd-435e-fc7c-501e275f93bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U2vawsWpLT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "589354b7-be67-48da-fb69-5820adffa581"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/데이콘 팀플/데이콘 공유/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/데이콘 팀플/데이콘 공유/test.csv')\n",
        "\n",
        "x_train = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_train = x_train/255\n",
        "\n",
        "y = train['digit']\n",
        "y_train = np.zeros((len(y), len(y.unique())))\n",
        "\n",
        "for i, digit in enumerate(y):\n",
        "    y_train[i, digit] = 1\n",
        "x_test = test.drop(['id', 'letter'], axis=1).values\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test/255\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1)\n",
        "print(x_train.shape[0])\n",
        "print(x_val.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1843\n",
            "205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG5VbqKKI8J2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa8cff3a-a60b-48b8-ae27-0ede47e7a619"
      },
      "source": [
        "train_length = len(train)\n",
        "\n",
        "digit_list = [0 for i in range(10)]\n",
        "print(digit_list)\n",
        "\n",
        "for i in range(train_length):\n",
        "    digit = train.loc[i, 'digit']\n",
        "    if digit==0: digit_list[0] += 1\n",
        "    elif digit ==1: digit_list[1] += 1\n",
        "    elif digit ==2: digit_list[2] += 1\n",
        "    elif digit ==3: digit_list[3] += 1\n",
        "    elif digit ==4: digit_list[4] += 1\n",
        "    elif digit ==5: digit_list[5] += 1\n",
        "    elif digit ==6: digit_list[6] += 1\n",
        "    elif digit ==7: digit_list[7] += 1\n",
        "    elif digit ==8: digit_list[8] += 1\n",
        "    elif digit ==9: digit_list[9] += 1\n",
        "print(digit_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[191, 202, 233, 205, 207, 225, 212, 194, 182, 197]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9juzeW1oJA-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_folder(directory_path):\n",
        "    if not os.path.isdir(directory_path):\n",
        "        os.mkdir(directory_path) \n",
        "        \n",
        "path_train = os.path.join(os.getcwd(), '/content/drive/My Drive/데이콘 팀플/trainimg')\n",
        "path_val = os.path.join(os.getcwd(), '/content/drive/My Drive/데이콘 팀플/valimg')\n",
        "path_test = os.path.join(os.getcwd(), '/content/drive/My Drive/데이콘 팀플/testimg')\n",
        "\n",
        "\n",
        "\n",
        "make_folder(path_train)\n",
        "make_folder(path_val)\n",
        "make_folder(path_test)\n",
        "\n",
        "for i in range(10):\n",
        "    path_train_digit = os.path.join(path_train, str(i))\n",
        "    path_val_digit = os.path.join(path_val, str(i))\n",
        "    make_folder(path_train_digit)\n",
        "    make_folder(path_val_digit)\n",
        "    \n",
        "\n",
        "for i in range(len(train)):\n",
        "    digit = train.loc[i, 'digit']\n",
        "    #print(i)\n",
        "    letter = train.loc[i, 'letter'] # letter\n",
        "    img = train.loc[i, '0':].values.reshape(28, 28).astype(int)\n",
        "\n",
        "    path_train_digit = os.path.join(path_train, str(digit))\n",
        "    path_val_digit = os.path.join(path_val, str(digit))\n",
        "    # cv2.imwrite(img, 'save_name')\n",
        "    if digit == 0:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 1:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 2:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 3:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 4:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 5:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 6:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 7:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 8:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "    elif digit == 9:\n",
        "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
        "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
        "        ran_num = randint(0,4)\n",
        "        if ran_num ==0:\n",
        "            cv2.imwrite(path_val_image, img)\n",
        "        else:\n",
        "            cv2.imwrite(path_train_image, img)\n",
        "\n",
        "for i in range(len(test)):\n",
        "\n",
        "    letter = test.loc[i, 'letter'] # letter\n",
        "    img = test.loc[i, '0':].values.reshape(28, 28).astype(int)\n",
        "    path_test_digit = os.path.join(path_test, '%d_%c.jpg'%(i, letter))\n",
        "    cv2.imwrite(path_test_digit, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MI8aJgYfbE6",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDe1uTHgJsgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "50bbdeb6-0fac-4635-8e9a-80ca3e8591a3"
      },
      "source": [
        "idx = 1\n",
        "img = train.loc[idx, '0':].values.reshape(28, 28).astype(int) # 0~783\n",
        "print(img.shape)\n",
        "digit = train.loc[idx, 'digit'] # digit\n",
        "letter = train.loc[idx, 'letter'] # letter\n",
        "\n",
        "plt.title('Index: %i, Digit: %s, Letter: %s'%(idx, digit, letter))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ronkxethJyII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "ea3897cc-f936-408f-83a4-925d9c4d66a4"
      },
      "source": [
        "img_size = 64\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        #agu.ImageNetPolicy(),\n",
        "        \n",
        "        transforms.Resize([img_size,img_size]),\n",
        "        #transforms.RandomResizedCrop(int(img_size*0.8)),\n",
        "        #transforms.RandomRotation(30),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        #transforms.Resize([img_size,img_size]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize([img_size,img_size]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = os.path.join(os.getcwd(), 'data/emnist')\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
        "                                             shuffle=True, num_workers=16)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(dataset_sizes, class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e704a418352a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[1;32m     26\u001b[0m                                           data_transforms[x])\n\u001b[0;32m---> 27\u001b[0;31m                   for x in ['train', 'val']}\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
            "\u001b[0;32m<ipython-input-46-e704a418352a>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[1;32m     26\u001b[0m                                           data_transforms[x])\n\u001b[0;32m---> 27\u001b[0;31m                   for x in ['train', 'val']}\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/emnist/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsbG24OwFGJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_datagen = ImageDataGenerator(\n",
        "\n",
        "#                                  width_shift_range=5,\n",
        "#                                  height_shift_range=5,\n",
        "#                                  rotation_range=10,\n",
        "#                                  zoom_range=0.05\n",
        "#     )\n",
        "# test_datagen = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6rIfGGDE-Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지 생성기의 선언\n",
        "# datagen = ImageDataGenerator(\n",
        "#                                  width_shift_range=5,\n",
        "#                                  height_shift_range=5,\n",
        "#                                  rotation_range=10,\n",
        "#                                  zoom_range=0.05)  \n",
        "\n",
        "\n",
        "# # flow형태의 정의\n",
        "# flow1=datagen.flow(X_image,X_letter,batch_size=32,seed=2020) \n",
        "# flow2=datagen.flow(X_image,Y,batch_size=32,seed=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m1ZYgTnDVIt",
        "colab_type": "text"
      },
      "source": [
        "이미지 문자 라벨 생성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1uHLskwTAlG",
        "colab_type": "text"
      },
      "source": [
        "제너레이트 한 모델을 위해 모델1 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R67Q4aSvGxVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "68ce8754-60e3-4639-fed4-e02e079f331a"
      },
      "source": [
        "# dropout_rate=0.5\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D(256, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
        "model1.add(Conv2D(256, kernel_size = 3, activation='relu'))\n",
        "model1.add(Conv2D(256, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "model1.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
        "model1.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
        "model1.add(Conv2D(128, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "model1.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
        "model1.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 26, 26, 256)       2560      \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 24, 24, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 12, 12, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 10, 10, 128)       295040    \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 4, 4, 128)         409728    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 1, 1, 128)         262272    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 3,347,210\n",
            "Trainable params: 3,347,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJNx6BH1KF3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b875d52f-702e-4da0-8c1f-a52f73349eb8"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1,patience=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-baf07f499b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X8vgew1KPkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=8):\n",
        "\n",
        "\n",
        "    global_info = []\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    early_stopping = EarlyStopping(patience=11, verbose=True)\n",
        "    for epoch in range(num_epochs):\n",
        "        local_info = []\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                if epoch >0:\n",
        "                    scheduler.step(val_loss)\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                \n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            if phase == 'val':\n",
        "                val_loss = running_loss / dataset_sizes['val']\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            #(Variable(x).data).cpu().numpy()\n",
        "            if phase == 'train':\n",
        "                local_info.append(epoch_loss)\n",
        "                ea = epoch_acc.cpu().numpy()\n",
        "                local_info.append(ea)\n",
        "            else:\n",
        "                local_info.append(epoch_loss)\n",
        "                ea = epoch_acc.cpu().numpy()\n",
        "                local_info.append(ea)\n",
        "\n",
        "\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        lr_get = get_lr(optimizer)\n",
        "        print(\"Current learning rate : {:.8f}\".format(lr_get))\n",
        "        global_info.append(local_info)\n",
        "        if phase =='val':\n",
        "            early_stopping(epoch_loss, model)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "    \n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G_yGj_QKTeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train_model(model1, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p42PxV-TK14y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name='test0913_1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6lCE37IKYsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, '/content/drive/My Drive/데이콘 팀플/models/{}.pth'.format(name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXa-DYcCLBM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import natsort as nt\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable \n",
        "def test_model():\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize([img_size,img_size]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ])\n",
        "    model_ft = torch.load('/content/drive/My Drive/데이콘 팀플/models/{}.pth'.format(name), map_location=device)\n",
        "    \n",
        "    path_test = os.path.join(os.getcwd(), 'data/emnist/test')\n",
        "    image_list = nt.natsorted(os.listdir(path_test))\n",
        "    output_list = []\n",
        "    for i, images in enumerate(image_list):\n",
        "        path_test_image = os.path.join(path_test, images)\n",
        "        image = Image.open(path_test_image)\n",
        "        image = data_transforms(image)\n",
        "        image.unsqueeze_(dim=0)\n",
        "        image = Variable(image)\n",
        "        image = image.cuda(device)\n",
        "        torch.no_grad()\n",
        "        output = model(image)\n",
        "        #print(output)\n",
        "        output = torch.argmax(output, dim=1)\n",
        "        \n",
        "        output_list.append(output)\n",
        "        \n",
        "    return output_list\n",
        "output = test_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiyX8Ln8Hz1O",
        "colab_type": "text"
      },
      "source": [
        "model save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhpKgf84LAj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TvCDwEXwviX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "e0b96f48-4ed1-455a-b789-87cffc91ae00"
      },
      "source": [
        "#제너레이트 안한 모델1 저장\n",
        "submission = pd.read_csv('/content/drive/My Drive/데이콘 팀플/데이콘 공유/submission.csv')\n",
        "submission.digit = torch.cat(output).detach().cpu().numpy()\n",
        "submission.to_csv('/content/drive/My Drive/데이콘 팀플/models/{}.csv'.format(name), index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20475</th>\n",
              "      <td>22524</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20476</th>\n",
              "      <td>22525</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20477</th>\n",
              "      <td>22526</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20478</th>\n",
              "      <td>22527</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20479</th>\n",
              "      <td>22528</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20480 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  digit\n",
              "0       2049      6\n",
              "1       2050      9\n",
              "2       2051      3\n",
              "3       2052      0\n",
              "4       2053      3\n",
              "...      ...    ...\n",
              "20475  22524      4\n",
              "20476  22525      1\n",
              "20477  22526      6\n",
              "20478  22527      3\n",
              "20479  22528      0\n",
              "\n",
              "[20480 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOMP3iEQHy6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'DinoLove_1'#이름\n",
        "submission.to_csv('/content/drive/My Drive/데이콘 팀플/데이콘 공유/{}.csv'.format(name), index=False)#경로\n",
        "model.save('/content/drive/My Drive/데이콘 팀플/데이콘 공유/{}.h5'.format(name))#경로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ArM6J1oR7wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "baa37839-f2fb-4c4b-8776-785b9d05cfa0"
      },
      "source": [
        "#제너레이트 한 모델2 저장\n",
        "submission = pd.read_csv('/content/drive/My Drive/데이콘 팀플/데이콘 공유/submission.csv')\n",
        "submission['digit'] = np.argmax(model2.predict(x_test),axis=1)\n",
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-82a92f75748b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#제너레이트 한 모델2 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/데이콘 팀플/데이콘 공유/submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'digit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI0EGCeXR___",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'DinoLove_2'#이름\n",
        "submission.to_csv('/content/drive/My Drive/데이콘 팀플/데이콘 공유/{}.csv'.format(name), index=False)#경로\n",
        "model2.save('/content/drive/My Drive/데이콘 팀플/데이콘 공유/{}.h5'.format(name))#경로"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}