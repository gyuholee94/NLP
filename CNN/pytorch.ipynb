{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.5.0-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.15.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import cv2\n",
    "import os\n",
    "from random import *\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit  :  [0 1 2 3 4 5 6 7 8 9]\n",
      "letter :  ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n"
     ]
    }
   ],
   "source": [
    "train_digit = train['digit'].values\n",
    "train_letter = train['letter'].values\n",
    "print('digit  : ', np.unique(train_digit))\n",
    "print('letter : ', np.unique(train_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[191, 202, 233, 205, 207, 225, 212, 194, 182, 197]\n"
     ]
    }
   ],
   "source": [
    "train_length = len(train)\n",
    "\n",
    "digit_list = [0 for i in range(10)]\n",
    "print(digit_list)\n",
    "\n",
    "for i in range(train_length):\n",
    "    digit = train.loc[i, 'digit']\n",
    "    if digit==0: digit_list[0] += 1\n",
    "    elif digit ==1: digit_list[1] += 1\n",
    "    elif digit ==2: digit_list[2] += 1\n",
    "    elif digit ==3: digit_list[3] += 1\n",
    "    elif digit ==4: digit_list[4] += 1\n",
    "    elif digit ==5: digit_list[5] += 1\n",
    "    elif digit ==6: digit_list[6] += 1\n",
    "    elif digit ==7: digit_list[7] += 1\n",
    "    elif digit ==8: digit_list[8] += 1\n",
    "    elif digit ==9: digit_list[9] += 1\n",
    "print(digit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(directory_path):\n",
    "    if not os.path.isdir(directory_path):\n",
    "        os.mkdir(directory_path) \n",
    "        \n",
    "path_train = os.path.join(os.getcwd(), './emnist/train')\n",
    "path_val = os.path.join(os.getcwd(), './emnist/val')\n",
    "path_test = os.path.join(os.getcwd(), './emnist/test')\n",
    "\n",
    "\n",
    "\n",
    "make_folder(path_train)\n",
    "make_folder(path_val)\n",
    "make_folder(path_test)\n",
    "\n",
    "for i in range(10):\n",
    "    path_train_digit = os.path.join(path_train, str(i))\n",
    "    path_val_digit = os.path.join(path_val, str(i))\n",
    "    make_folder(path_train_digit)\n",
    "    make_folder(path_val_digit)\n",
    "    \n",
    "\n",
    "for i in range(len(train)):\n",
    "    digit = train.loc[i, 'digit']\n",
    "    #print(i)\n",
    "    letter = train.loc[i, 'letter'] # letter\n",
    "    img = train.loc[i, '0':].values.reshape(28, 28).astype(int)\n",
    "\n",
    "    path_train_digit = os.path.join(path_train, str(digit))\n",
    "    path_val_digit = os.path.join(path_val, str(digit))\n",
    "    # cv2.imwrite(img, 'save_name')\n",
    "    if digit == 0:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 1:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 2:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 3:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 4:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 5:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 6:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 7:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 8:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "    elif digit == 9:\n",
    "        path_train_image = os.path.join(path_train_digit, '%d_%c.jpg'%(i,letter))\n",
    "        path_val_image = os.path.join(path_val_digit, '%d_%c.jpg'%(i, letter))\n",
    "        ran_num = randint(0,4)\n",
    "        if ran_num ==0:\n",
    "            cv2.imwrite(path_val_image, img)\n",
    "        else:\n",
    "            cv2.imwrite(path_train_image, img)\n",
    "\n",
    "for i in range(len(test)):\n",
    "\n",
    "    letter = test.loc[i, 'letter'] # letter\n",
    "    img = test.loc[i, '0':].values.reshape(28, 28).astype(int)\n",
    "    path_test_digit = os.path.join(path_test, '%d_%c.jpg'%(i, letter))\n",
    "    cv2.imwrite(path_test_digit, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "img = train.loc[idx, '0':].values.reshape(28, 28).astype(int) # 0~783\n",
    "print(img.shape)\n",
    "digit = train.loc[idx, 'digit'] # digit\n",
    "letter = train.loc[idx, 'letter'] # letter\n",
    "\n",
    "plt.title('Index: %i, Digit: %s, Letter: %s'%(idx, digit, letter))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 files in subfolders of: C:\\Users\\user\\NLP\\데이콘\\CNN\\./emnist\\train\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-01c3d76a122d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./emnist'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0m\u001b[0;32m     26\u001b[0m                                           data_transforms[x])\n\u001b[0;32m     27\u001b[0m                   for x in ['train', 'val']}\n",
      "\u001b[1;32m<ipython-input-17-01c3d76a122d>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./emnist'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0m\u001b[0;32m     26\u001b[0m                                           data_transforms[x])\n\u001b[0;32m     27\u001b[0m                   for x in ['train', 'val']}\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    204\u001b[0m     def __init__(self, root, transform=None, target_transform=None,\n\u001b[0;32m    205\u001b[0m                  loader=default_loader, is_valid_file=None):\n\u001b[1;32m--> 206\u001b[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[0;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise (RuntimeError(\"Found 0 files in subfolders of: \" + self.root + \"\\n\"\n\u001b[0m\u001b[0;32m     97\u001b[0m                                 \"Supported extensions are: \" + \",\".join(extensions)))\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found 0 files in subfolders of: C:\\Users\\user\\NLP\\데이콘\\CNN\\./emnist\\train\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp"
     ]
    }
   ],
   "source": [
    "img_size = 64\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #agu.ImageNetPolicy(),\n",
    "        \n",
    "        transforms.Resize([img_size,img_size]),\n",
    "        #transforms.RandomResizedCrop(int(img_size*0.8)),\n",
    "        #transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        #transforms.Resize([img_size,img_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize([img_size,img_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), './emnist')\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=16)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "print(dataset_sizes, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.layer1 = self.conv_module(1, 16)\n",
    "        self.layer3 = self.conv_module(16, 24)\n",
    "        self.layer4 = self.conv_module(24, 32)\n",
    "        self.layer5 = self.conv_module(32, 64)\n",
    "        self.layer6 = self.conv_module(64,128)\n",
    "        self.gap = self.global_avg_pool(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1, 10)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def conv_module(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1))\n",
    "\n",
    "    def global_avg_pool(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer6): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (gap): Sequential(\n",
      "    (0): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CustomCNN()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=8):\n",
    "\n",
    "\n",
    "    global_info = []\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stopping = EarlyStopping(patience=11, verbose=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        local_info = []\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                if epoch >0:\n",
    "                    scheduler.step(val_loss)\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            if phase == 'val':\n",
    "                val_loss = running_loss / dataset_sizes['val']\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            #(Variable(x).data).cpu().numpy()\n",
    "            if phase == 'train':\n",
    "                local_info.append(epoch_loss)\n",
    "                ea = epoch_acc.cpu().numpy()\n",
    "                local_info.append(ea)\n",
    "            else:\n",
    "                local_info.append(epoch_loss)\n",
    "                ea = epoch_acc.cpu().numpy()\n",
    "                local_info.append(ea)\n",
    "\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        lr_get = get_lr(optimizer)\n",
    "        print(\"Current learning rate : {:.8f}\".format(lr_get))\n",
    "        global_info.append(local_info)\n",
    "        if phase =='val':\n",
    "            early_stopping(epoch_loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-285d5ec16275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[0;32m      2\u001b[0m                        num_epochs=100)\n",
      "\u001b[1;32m<ipython-input-23-4e1699afc696>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# Iterate over data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
